{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92169b44-b45b-420c-9ee4-10dfe4394a1c",
   "metadata": {},
   "source": [
    "# LLM Capstone Project Notebook: Guided Template\n",
    "\n",
    "In this session, each participant will present their project to the group, introducing the goals, technical foundations, and expected impact of their work. These presentations serve as a launchpad for collaboration, feedback, and iteration throughout the course.\n",
    "\n",
    "---\n",
    "\n",
    "### üó£Ô∏è Presentation Guidelines\n",
    "\n",
    "Each participant will have **up to 10 minutes** to present their project. Please ensure your presentation addresses the following key areas:\n",
    "\n",
    "1. **üìå Project Topic & Purpose**  \n",
    "   - What is the problem you're solving?  \n",
    "   - Why is this relevant to your domain or a broader societal challenge?\n",
    "\n",
    "2. **üß† Model Selection & Justification**  \n",
    "   - What model(s) are you using (e.g., GPT-4.1, Mistral, fine-tuned LLM)?  \n",
    "   - Why was this model chosen for your use case?\n",
    "\n",
    "3. **üîß Techniques & Implementation**  \n",
    "   - Highlight which techniques are being used:\n",
    "     - Retrieval-Augmented Generation (RAG)\n",
    "     - Fine-tuning\n",
    "     - Tool-using agents or LangGraph workflows\n",
    "     - Prompt engineering and safety mechanisms\n",
    "   - Explain how these choices support your goal (e.g., safety, accuracy, interactivity)\n",
    "\n",
    "4. **üñ•Ô∏è Live Demo (Optional but Encouraged)**  \n",
    "   - Walk us through your system‚Äôs functionality  \n",
    "   - Show how users interact with your app, and what makes it unique  \n",
    "   - Highlight specific features that improve alignment, reliability, or UX\n",
    "5. **Final Deliverables Checklist**\n",
    "\n",
    "   - 10-minute project presentation  \n",
    "   - Notebook or script implementing core features    \n",
    "   - Evaluation results (DeepEval or similar)\n",
    "   - Streamlit app with basic UI\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4cc6f-7880-45f0-9541-0f5370973842",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n",
    "```python\n",
    "# üìå Define your project\n",
    "project_title = \"MedSafety LLM Alignment\"\n",
    "team_members = [\"Katherine Rosenfeld\", \"Jessica Lundin\"]\n",
    "project_description = \"\"\"\n",
    "This project aims to assess and improve the ethical alignment of LLMs for medical use cases. \n",
    "We will benchmark several alignment techniques using the MedSafety-Eval dataset.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7529c39-98d1-4eac-8285-b8167c47959e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24f9927b-a209-4af1-8ba1-7b73e7c3fb79",
   "metadata": {},
   "source": [
    "## 2: Data Collection & Loading\n",
    "\n",
    "### üîç Step 1: Define Your Approach\n",
    "\n",
    "Choose your methodology. This will shape how you collect and prepare your data. You may use one or combine several of the following:\n",
    "\n",
    "- **Prompting** ‚Äì Craft prompts and test model outputs.  \n",
    "- **RAG (Retrieval-Augmented Generation)** ‚Äì Build a vector database to augment responses with external knowledge.  \n",
    "- **Fine-Tuning** ‚Äì Train an LLM on your custom dataset for better domain-specific behavior.\n",
    "\n",
    "> ‚ö†Ô∏è Each approach requires different preprocessing. Plan accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Step 2: Load Your Dataset\n",
    "\n",
    "Load your raw data file (e.g., JSON or CSV).  \n",
    "Make sure to inspect the structure so you can prep it correctly later.\n",
    "\n",
    "\n",
    "### üßπ Step 3: Prepare Data Based on Method\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ú® Prompting\n",
    "\n",
    "- No complex processing needed.  \n",
    "- Focus on writing high-quality prompts and (optionally) reference answers.\n",
    "\n",
    "**Techniques to Try:**\n",
    "\n",
    "- **Zero-shot** ‚Äì Ask the model directly, without examples.  \n",
    "- **Few-shot** ‚Äì Provide a few input/output examples before your main task.  \n",
    "- **Meta prompting** ‚Äì Ask the model to generate, revise, or critique prompts and responses.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìö RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "- Clean and split text into chunks for embedding.  \n",
    "- Use a text splitter (e.g., `CharacterTextSplitter` from LangChain).  \n",
    "- Embed documents using a model like `OpenAIEmbeddings`.  \n",
    "- Store vectors in a vector DB (e.g., Chroma).  \n",
    "- Optionally attach metadata (e.g., section titles, source) for better filtering.\n",
    "\n",
    "> üîß Tip: Use consistent chunk sizes and overlap to balance context and retrievability.\n",
    "\n",
    "\n",
    "#### üõ†Ô∏è Fine-Tuning\n",
    "\n",
    "- Clean, normalize, and format your dataset into `{\"input\": ..., \"output\": ...}` pairs.  \n",
    "- Save in `.jsonl` format and split into train/test subsets.  \n",
    "- Use the OpenAI CLI or API to start fine-tuning.\n",
    "\n",
    "**Supported OpenAI Models (2025):**\n",
    "\n",
    "- `gpt-4.1`  \n",
    "- `gpt-4.1-mini`  \n",
    "- `gpt-4.1-nano`  \n",
    "- `o3`  \n",
    "- `o3-mini`\n",
    "\n",
    "**Example CLI Commands:**\n",
    "\n",
    "#### Step 1: Prepare dataset\n",
    "openai tools fine_tunes.prepare_data -f data.jsonl\n",
    "\n",
    "#### Step 2: Start fine-tuning\n",
    "openai api fine_tunes.create -t \"data_prepared.jsonl\" -m \"gpt-4.1\"\n",
    "\n",
    "#### Step 3: Monitor job\n",
    "openai api fine_tunes.follow -i <FINE_TUNE_JOB_ID>\n",
    "\n",
    "**More info**: https://platform.openai.com/docs/guides/fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7963-6da5-40b5-bbe5-22f5073e0121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6ba504b-611e-4949-bf5b-dbd4edb326f1",
   "metadata": {},
   "source": [
    "##  3: Design Your LLM Application Architecture\n",
    "\n",
    "With your data prepped, the next step is to design **how your system will use the LLM**. This includes choosing between simple prompt chains, agent-based reasoning, and advanced graph workflows for complex decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Choose Your Architecture Strategy\n",
    "\n",
    "Pick your approach based on how dynamic and modular your application needs to be:\n",
    "\n",
    "- **üí¨ Prompt-only** ‚Äì Simple, direct calls with structured prompt templates.  \n",
    "- **üß± LangChain Core** ‚Äì Modular chains for IO, memory, and logic reuse.  \n",
    "- **ü§ñ LangChain Agents** ‚Äì Let LLMs choose tools and actions dynamically.  \n",
    "- **üï∏Ô∏è LangGraph** ‚Äì Build complex, stateful, multi-agent workflows with decision branches and memory.\n",
    "\n",
    "> ‚ö†Ô∏è These options are **composable** ‚Äî start simple and grow into more advanced designs.\n",
    "\n",
    "---\n",
    "\n",
    "### üß≠ Decision Flow\n",
    "\n",
    "1. **Is the task straightforward and stateless?** ‚Üí Use **prompt templates**.  \n",
    "2. **Do you need logic or memory between steps?** ‚Üí Use **LangChain chains**.  \n",
    "3. **Should the model decide which tool or step to use?** ‚Üí Use **Agents**.  \n",
    "4. **Do you need multiple agents, loops, branches, or shared state?** ‚Üí Use **LangGraph**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ LangGraph: Multi-Agent State Machines\n",
    "\n",
    "LangGraph lets you define workflows as graphs, where each node can:\n",
    "\n",
    "- Run a function (LLM or tool)\n",
    "- Update and pass along state\n",
    "- Branch logic based on outputs\n",
    "- Use memory across steps and agents\n",
    "\n",
    "It's perfect for:\n",
    "\n",
    "- Multi-agent planning\n",
    "- Document processing pipelines\n",
    "- Stateful chat agents\n",
    "- Research assistants with feedback loops\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6bcec-ceb8-40e6-8074-e5a135c2d583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a390af9-2392-4036-819c-dbb07ecd6e0e",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 4: Implement Core Capabilities  \n",
    "**(RAG Pipeline, Fine-Tuning, Guardrails, Multi-Agent LangGraph)**\n",
    "\n",
    "Now that you've defined your architecture, it's time to **build the core functionality** of your system. In this project, your goal is to improve the alignment and safety of LLMs in a medical context using techniques such as:\n",
    "\n",
    "- Retrieval-Augmented Generation (RAG)  \n",
    "- Fine-tuning with alignment data  \n",
    "- Guardrails (rule-based and prompt-based)  \n",
    "- Multi-agent coordination using LangGraph  \n",
    "\n",
    "---\n",
    "\n",
    "### üîç 4.1: Build the RAG System\n",
    "\n",
    "Ground your model's responses using trusted sources like scientific literature or medical guidelines.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Chunk and embed your documents (e.g., MedSafetyEval explanations, WHO safety codes).\n",
    "2. Store them in a vector database (e.g., Chroma, FAISS).\n",
    "3. Retrieve relevant context dynamically.\n",
    "4. Generate grounded responses using LangChain chains or agents.\n",
    "\n",
    "### üîç 4.2: Fine Tune\n",
    "\n",
    "Ground your model's responses using trusted sources like scientific literature or medical guidelines.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Format the data\n",
    "2. Train, test, split your data\n",
    "3. Fine tune the model\n",
    "4. Watch the loss function and see if the model is really learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c4d21-6ddd-47d1-9d76-4857477debf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "196248f8-1d6c-4abf-8253-157c198c8131",
   "metadata": {},
   "source": [
    "## 5: Evaluation \n",
    "**(with DeepEval)**\n",
    "\n",
    "After building your RAG pipeline, fine-tuning the model, and/or implementing multi-agent workflows, it's time to **evaluate your system**. In this phase, you will use benchmark datasets and custom metrics to assess **alignment, safety, and factual accuracy**.\n",
    "\n",
    "You will primarily use **[DeepEval](https://github.com/confident-ai/deepeval)**\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Goals of Evaluation\n",
    "\n",
    "- Measure harmfulness, factuality, and alignment with ethical standards.\n",
    "- Compare the impact of RAG, fine-tuning, and multi-agent workflows.\n",
    "- Analyze failure cases and edge scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Evaluation Setup\n",
    "\n",
    "You will define a suite of evaluation tasks based on the project dataset. Each task should include:\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Step-by-Step Instructions\n",
    "\n",
    "#### 1. Define Your Evaluation Metrics\n",
    "\n",
    "Use DeepEval‚Äôs built-in metrics or define your own. \n",
    "\n",
    "#### 2. Create Evaluation Cases\n",
    "\n",
    "- Start with a **subset of MedSafetyEval** for quick iteration.\n",
    "- Create test cases as a JSON or CSV file with:\n",
    "  - Prompt\n",
    "  - Expected output\n",
    "  - Metadata (risk category, topic, etc.)\n",
    "\n",
    "#### 3. Run Evaluations\n",
    "\n",
    "- Evaluate each system variant:\n",
    "  - Base model\n",
    "  - RAG only\n",
    "  - Fine-tuned only\n",
    "  - RAG + fine-tuned\n",
    "  - Multi-agent with safety checks\n",
    "\n",
    "- For each case, collect:\n",
    "  - Predicted response\n",
    "  - Score for each metric\n",
    "  - Reviewer notes (optional)\n",
    "\n",
    "#### 4. Compare Results\n",
    "\n",
    "- Create comparison tables and visualizations:\n",
    "  - Score per method\n",
    "  - Failure analysis\n",
    "  - Strengths/weaknesses per technique\n",
    "\n",
    "- Reflect on questions like:\n",
    "  - Which method produces better results?\n",
    "  - Does RAG improve factuality?\n",
    "  - Are multi-agent workflows worth the complexity?\n",
    "\n",
    "#### 5. Document Insights\n",
    "\n",
    "For each technique tested (RAG, fine-tune, guardrails, multi-agent):\n",
    "\n",
    "- Summarize its **impact** on safety and alignment\n",
    "- List **limitations or blind spots**\n",
    "- Suggest **improvements or next steps**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9e530-fc15-4b9b-9dcd-533aceedf980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920f9b9b-94e6-49d1-8633-95c23055a6c0",
   "metadata": {},
   "source": [
    "## 6: Deployment with Streamlit  \n",
    "**Make Your Project Interactive and Accessible**\n",
    "\n",
    "In this session, you'll package your project into a web application using **[Streamlit](https://streamlit.io/)** ‚Äî a powerful and simple framework for turning Python scripts into interactive apps.\n",
    "\n",
    "The goal is to **make your LLM system usable** through a web interface, allowing others to test, interact with, and evaluate your model easily.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± What You'll Build\n",
    "\n",
    "By the end of this session, your project will have a working **Streamlit frontend** that:\n",
    "\n",
    "- Accepts user queries (e.g., medical questions, research topics)\n",
    "- Displays model responses and retrieved sources (if using RAG)\n",
    "- Logs or visualizes evaluation scores (optional)\n",
    "- Allows testing of multiple models or settings (baseline vs. fine-tuned, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "### üß∞ Key Components of a Streamlit App\n",
    "\n",
    "Your app should include:\n",
    "\n",
    "1. **üì• Input Box**  \n",
    "   For users to type a query or select a predefined case.\n",
    "\n",
    "2. **ü§ñ Model Output**  \n",
    "   Display the LLM‚Äôs response clearly, with formatting and citations if relevant.\n",
    "\n",
    "3. **üìö Contextual Data (for RAG)**  \n",
    "   If using RAG, show retrieved documents and source info for transparency.\n",
    "\n",
    "4. **üß™ Evaluation or Feedback Module (Optional)**  \n",
    "   Allow users to rate output quality, report unsafe content, or toggle system variants.\n",
    "\n",
    "5. **üß∞ Backend Logic**  \n",
    "   Include your pipeline (RAG, fine-tuned model, agents) as callable Python functions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b8c7f-e817-4acc-9133-d13d20e1746e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
